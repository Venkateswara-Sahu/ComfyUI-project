# ComfyUI AI Model Deployment

## ğŸš€ Project Overview
This project focuses on deploying AI models using **ComfyUI** with support for **LoRA models, Stable Diffusion, Fooocus, TensorFlow, PyTorch**, and more. It includes a backend API for integration and serves AI-generated outputs efficiently.

## ğŸ”¥ Features
- âœ… **ComfyUI Workflows** for AI image processing.
- âœ… **LoRA & Checkpoint Integration** for enhanced AI-generated outputs.
- âœ… **FastAPI Backend** for AI model inference via REST APIs.
- âœ… **CUDA Acceleration (if available)** for optimized performance.
- âœ… **Real-time AI Image Processing & Deployment**.

## ğŸ› ï¸ Technologies Used
- **ComfyUI**
- **Stable Diffusion / Fooocus**
- **LoRA & Checkpoints**
- **FastAPI / Flask (Backend APIs)**
- **TensorFlow / PyTorch**
- **CUDA (if available)**
- **Docker & Deployment Tools**

## ğŸ“‚ Project Structure
```
ComfyUI-project/
â”‚â”€â”€ api_server/       # Backend API for model inference
â”‚â”€â”€ comfy/            # AI processing engine
â”‚â”€â”€ models/           # AI models, LoRA, and checkpoints
â”‚â”€â”€ notebooks/        # Jupyter notebooks for experimentation
â”‚â”€â”€ scripts/          # Utility scripts for AI processing
â”‚â”€â”€ README.md         # Project Documentation
```

## ğŸš€ Setup & Installation
### ğŸ”¹ Clone the Repository
```bash
git clone https://github.com/Venkateswara-Sahu/ComfyUI-project.git
cd ComfyUI-project
```

### ğŸ”¹ Install Dependencies
```bash
pip install -r requirements.txt
```

### ğŸ”¹ Run the ComfyUI Backend
```bash
python main.py
```

### ğŸ”¹ Start the API Server
```bash
uvicorn api_server.main:app --host 0.0.0.0 --port 8000
```

## ğŸ¯ API Endpoints
| Endpoint          | Method | Description                |
|------------------|--------|----------------------------|
| `/generate`      | POST   | Generates AI images       |
| `/upload_model`  | POST   | Uploads custom LoRA model |
| `/status`        | GET    | Checks API health         |

